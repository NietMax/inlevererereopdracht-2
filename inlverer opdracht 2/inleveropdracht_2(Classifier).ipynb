{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetisch algioritme voor optimale hyper-parameters verkrijgen uit de iris dataset\n",
    "\n",
    "Deze code-cel begint met het importeren van de benodigde Python-bibliotheken en instellingen voor het uitvoeren van hyperparameteroptimalisatie voor een neuraal netwerkmodel. Hier zijn de belangrijkste elementen die in deze cel gebeuren:\n",
    "\n",
    "1. **Importeren van Numpy en scikit-learn Libraries**:\n",
    "   - De code importeert `numpy` als `np` voor numerieke berekeningen.\n",
    "   - Het laadt de Iris-dataset met behulp van de `load_iris` functie van scikit-learn. Deze dataset zal worden gebruikt voor het evalueren van het neuraal netwerkmodel.\n",
    "   - Het importeert `train_test_split` om de dataset te splitsen in trainings- en testgegevens.\n",
    "   - Het gebruikt `MLPClassifier` van scikit-learn om een meerlaagse perceptron-neuraal netwerk voor classificatie te definiëren en te configureren.\n",
    "\n",
    "2. **Importeren van de Tabulate-bibliotheek**:\n",
    "   - De code importeert de `tabulate`-bibliotheek. Deze bibliotheek wordt later gebruikt om de resulterende error metrics op een nette manier als een tabel weer te geven.\n",
    "\n",
    "3. **Importeren van Regressiemetrieken uit sklearn**\n",
    "   - De code importeert de scoringsmetrieken `accuracy_score`, `precision_score`, `recall_score`, `f1_score` en `confusion_matrix` uit sklearn om het genetisch algoritme te scoren.\n",
    "\n",
    "3. **Uitschakelen van Waarschuwingen**:\n",
    "   - Er wordt een waarschuwingssuppressie geactiveerd om te voorkomen dat waarschuwingen de uitvoer onnodig vervuilen.\n",
    "\n",
    "Deze voorbereidende stappen zijn cruciaal voor het correct uitvoeren van de hyperparameteroptimalisatie voor het neurale netwerkmodel en voor het weergeven van de resultaten in een overzichtelijke tabel met error metrics aan het einde van het script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports for the hyperparameter optimization\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Import the tabulate library for a nice table at the end of the file for the error metrics\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Importeer relevante evaluatiemetrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Ignoring all warnings because it clutters the space where the results are supposed to go in to\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gebruik van de Iris Dataset en Dataverdeling\n",
    "\n",
    "In deze code-cel wordt de Iris-dataset gebruikt en wordt de dataset verdeeld in trainings- en testgegevens. Hier zijn de belangrijkste elementen die in deze cel gebeuren:\n",
    "\n",
    "1. **Laden van de Iris Dataset**:\n",
    "   - De code laadt de Iris-dataset met behulp van de `load_iris` functie. De Iris-dataset bevat informatie over irisbloemen en wordt vaak gebruikt voor machinaal leren toepassingen.\n",
    "\n",
    "2. **Dataverdeling**:\n",
    "   - De code splitst de gegevens in onafhankelijke variabelen (`X`) en de doelvariabele (`y`). `X` bevat de kenmerken van de bloemen, terwijl `y` de bijbehorende klasselabels bevat.\n",
    "   - De dataset wordt verder opgesplitst in trainings- en testgegevens met behulp van `train_test_split`. Hierbij wordt 80% van de gegevens toegewezen aan de trainingsset en 20% aan de testset.\n",
    "   - De `random_state` wordt ingesteld op 42 (“the Ultimate Question of Life, the Universe, and Everything.\") om ervoor te zorgen dat de verdeling van de gegevens reproduceerbaar is.\n",
    "\n",
    "Deze stappen zijn essentieel voor het voorbereiden van de gegevens voor de training en evaluatie van het neurale netwerkmodel. De Iris-dataset wordt gebruikt als de basis voor dit machine learning-assignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're using the iris dataset for this assignment\n",
    "data = load_iris()\n",
    "\n",
    "# Splitting the data into training and testing data\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitie van te Testen Hyperparameters\n",
    "\n",
    "In deze code-cel worden de hyperparameters gedefinieerd die zullen worden getest bij het optimaliseren van het neurale netwerkmodel. Hier zijn de belangrijkste elementen die in deze cel gebeuren:\n",
    "\n",
    "1. **Activatiefuncties**:\n",
    "   - De code definieert een lijst `activation_functions` met verschillende activatiefuncties die zullen worden getest. Deze functies beïnvloeden de overgang van informatie tussen neuronen in het netwerk. De beschikbare activatiefuncties zijn 'logistic', 'tanh', 'relu', en 'identity'.\n",
    "\n",
    "2. **Grootte van Verborgen Lagen**:\n",
    "   - De grootte van de verborgen lagen wordt gedefinieerd als een lijst van getallen in `hidden_layer_sizes`. Elke waarde in de lijst vertegenwoordigt de grootte van een verborgen laag in het neurale netwerk. Dit geeft flexibiliteit bij het testen van verschillende architecturen.\n",
    "\n",
    "3. **Optimalisatie Solvers**:\n",
    "   - De code definieert een lijst `solvers` met verschillende optimalisatiesolvers die worden gebruikt om de optimale gewichten voor het neurale netwerk te vinden. De beschikbare solvers zijn 'lbfgs', 'sgd', en 'adam'. Het standaard leerpercentage wordt gebruikt voor elk van deze solvers.\n",
    "\n",
    "Deze definitie van hyperparameters is cruciaal voor het begeleiden van de hyperparameteroptimalisatie van het neurale netwerkmodel. Door verschillende combinaties van activatiefuncties, verborgen laaggroottes en solvers te testen, kan de optimale configuratie van het model worden bepaald.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the hyperparameters that we want to test\n",
    "activation_functions = ['logistic', 'tanh', 'relu', 'identity']\n",
    "# The hidden layer sizes are defined as a list of tuples, where each tuple represents a hidden layer\n",
    "hidden_layer_sizes = [10, 20, 30, 40]\n",
    "# The solvers are the optimizers that are used to find the optimal weights\n",
    "# We're using the default learning rate for each solver\n",
    "solvers = ['lbfgs', 'sgd', 'adam']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluatie van Individuen en Genetisch Algoritme\n",
    "\n",
    "Deze code-cel bevat de implementatie van een functie voor het evalueren van de nauwkeurigheid van individuele neurale netwerkconfiguraties, evenals een genetisch algoritme voor het zoeken naar de beste individuele configuratie. Hier zijn de belangrijkste elementen die in deze cel gebeuren:\n",
    "\n",
    "**Functie voor Evaluatie van Individuen**:\n",
    "- De functie `evaluate_individual` ontvangt drie parameters: `activation_function`, `hidden_layer_size`, en `solver`.\n",
    "- Binnen deze functie wordt een `MLPClassifier`-model geïnitialiseerd en getraind met de opgegeven hyperparameters. Het model maakt gebruik van een enkele verborgen laag met de specificaties.\n",
    "- De nauwkeurigheid van het model wordt berekend op basis van de testgegevens (`X_test` en `y_test`) en geretourneerd als het evaluatieresultaat.\n",
    "\n",
    "**Genetisch Algoritme voor Hyperparameteroptimalisatie**:\n",
    "- De functie `genetic_algorithm` wordt gebruikt om het genetisch algoritme uit te voeren voor hyperparameteroptimalisatie.\n",
    "- Een initiële populatie van individuen wordt gecreëerd, waarbij de hyperparameters willekeurig worden gekozen uit de gedefinieerde sets van activatiefuncties, verborgen laaggroottes en solvers.\n",
    "- Het genetisch algoritme wordt vervolgens uitgevoerd over meerdere generaties, waarbij individuen worden geëvalueerd en de beste individuen worden geselecteerd op basis van hun nauwkeurigheid.\n",
    "- Nieuwe individuen worden gegenereerd door combinaties van ouders en een willekeurige mutatie wordt geïntroduceerd om diversiteit te behouden.\n",
    "- Het genetisch algoritme zoekt naar het beste individu met de hoogste nauwkeurigheid en retourneert de hyperparameters van dat individu als resultaat.\n",
    "\n",
    "Deze implementaties zijn cruciaal voor het automatisch zoeken naar de optimale hyperparameters van het neurale netwerkmodel. Het genetisch algoritme evolueert de populatie van individuen om de configuratie te vinden die leidt tot de beste nauwkeurigheid bij classificatie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function that evaluates the accuracy of an individual\n",
    "def evaluate_individual(activation_function, hidden_layer_size, solver):\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(hidden_layer_size,), activation=activation_function, solver=solver, max_iter=2000, random_state=42) # max_iter is not optimal at 2000 but this way the code doesn't run forever\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    return accuracy\n",
    "\n",
    "# The genetic algorithm that finds the best individual\n",
    "def genetic_algorithm(population_size, generations):\n",
    "    population = []\n",
    "\n",
    "    # Creating the initial population\n",
    "    for _ in range(population_size):\n",
    "        activation_function = np.random.choice(activation_functions)\n",
    "        hidden_layer_size = np.random.choice(hidden_layer_sizes)\n",
    "        solver = np.random.choice(solvers)\n",
    "        individual = (activation_function, hidden_layer_size, solver)\n",
    "        population.append(individual)\n",
    "\n",
    "    # Running the genetic algorithm\n",
    "    for generation in range(generations):\n",
    "        scores = [evaluate_individual(activation_function, hidden_layer_size, solver) for activation_function, hidden_layer_size, solver in population]\n",
    "        selected_indices = np.argsort(scores)[::-1][:int(population_size * 0.2)]\n",
    "        selected_population = [population[i] for i in selected_indices]\n",
    "\n",
    "        # Creating the new population\n",
    "        new_population = []\n",
    "        for _ in range(population_size):\n",
    "            index1, index2 = np.random.choice(len(selected_population), size=2, replace=False)\n",
    "            parent1 = selected_population[index1]\n",
    "            parent2 = selected_population[index2]\n",
    "            parent1_activation_function, parent1_hidden_layer_size, parent1_solver = parent1\n",
    "            parent2_activation_function, parent2_hidden_layer_size, parent2_solver = parent2\n",
    "            child = (parent1_activation_function, parent2_hidden_layer_size, parent2_solver)\n",
    "            new_population.append(child)\n",
    "\n",
    "        # Mutating the new population\n",
    "        population = new_population\n",
    "\n",
    "    # Finding the best individual\n",
    "    best_individual = max(population, key=lambda ind: evaluate_individual(ind[0], ind[1], ind[2]))\n",
    "    return best_individual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uitvoeren van het Genetisch Algoritme en Afdrukken van Resultaten\n",
    "\n",
    "In deze code-cel wordt het genetisch algoritme uitgevoerd om de optimale hyperparameters voor het neurale netwerkmodel te vinden, en worden de resultaten afgedrukt. Hier zijn de belangrijkste elementen die in deze cel gebeuren:\n",
    "\n",
    "**Uitvoeren van het Genetisch Algoritme**:\n",
    "- De functie `genetic_algorithm` wordt opgeroepen met twee parameters: `population_size` en `generations`. Hier worden respectievelijk de grootte van de populatie en het aantal generaties voor het genetisch algoritme gespecificeerd.\n",
    "- Het genetisch algoritme zal meerdere generaties doorlopen en proberen de optimale hyperparameters te vinden op basis van de prestaties van individuen.\n",
    "\n",
    "**Afdrukken van de Optimale Hyperparameters**:\n",
    "- Nadat het genetisch algoritme is voltooid, worden de optimale hyperparameters verkregen en opgeslagen in de variabele `best_hyperparameters`.\n",
    "- Deze optimale hyperparameters worden afgedrukt naar de console met de tekst \"Optimal hyperparameters:\", gevolgd door de daadwerkelijke hyperparameters.\n",
    "\n",
    "Deze code is de laatste stap in het proces van hyperparameteroptimalisatie en onthult de optimale configuratie die is gevonden door het genetisch algoritme. Dit is belangrijke informatie om de prestaties van het neurale netwerkmodel te verbeteren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal hyperparameters: ('identity', 20, 'sgd')\n"
     ]
    }
   ],
   "source": [
    "# Running the genetic algorithm and printing the results\n",
    "best_hyperparameters = genetic_algorithm(population_size=50, generations=10)\n",
    "print(\"Optimal hyperparameters:\", best_hyperparameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluatie van het Geoptimaliseerde Neurale Netwerk Model Algoritme (met de juiste error metrics)\n",
    "\n",
    "Deze code-cel is bedoeld voor de evaluatie van het prestaties van een geoptimaliseerd neuronaal netwerkmodel op een testdataset. De neuronaal netwerk hyperparameters, inclusief de activatiefunctie, de grootte van de verborgen laag en de solver, zijn geoptimaliseerd met behulp van een genetisch algoritme. De code toont hoe de prestaties van het model worden beoordeeld met behulp van verschillende evaluatiemetrics.\n",
    "\n",
    "1. **Model Training**:\n",
    "   - De code initialiseert en traint een neuronaal netwerkmodel (`best_clf`) met de geoptimaliseerde hyperparameters. De hyperparameters worden opgehaald uit `best_hyperparameters`, die zijn bepaald door het genetisch algoritme.\n",
    "   - Het model wordt getraind op de trainingsdataset (`X_train` en `y_train`).\n",
    "\n",
    "2. **Model Voorspelling**:\n",
    "   - Het getrainde model wordt gebruikt om voorspellingen te doen op de testdataset (`X_test`) om de prestaties te evalueren.\n",
    "\n",
    "3. **Importeren van Relevante Metrics**:\n",
    "   - Diverse evaluatiemetrics worden geïmporteerd uit scikit-learn, waaronder nauwkeurigheid, precisie, recall en F1-score. Deze metrics worden vaak gebruikt om de prestaties van classificatiemodellen te beoordelen.\n",
    "\n",
    "4. **Berekening van Metrics**:\n",
    "   - De code berekent de volgende evaluatiemetrics op basis van de voorspellingen van het model en de ware labels uit de testdataset:\n",
    "     - **Nauwkeurigheid**: Het deel van correct geclassificeerde voorbeelden.\n",
    "     - **Precisie**: Het vermogen van het model om positieve voorspellingen correct te maken.\n",
    "     - **Recall (Gevoeligheid)**: Het vermogen van het model om positieve voorbeelden correct te identificeren.\n",
    "     - **F1-score**: Het harmonische gemiddelde van precisie en recall, wat een gebalanceerde maatstaf voor de prestaties van het model biedt.\n",
    "\n",
    "5. **Confusion Matrix**:\n",
    "   - Een confusion matrix (verwarringsmatrix) wordt gemaakt met behulp van de functie `confusion_matrix`. De confusion matrix geeft een gedetailleerdere uitsplitsing van de prestaties van het model door het aantal ware positieven, valse negatieven, valse positieven en ware negatieven voor elke klasse weer te geven.\n",
    "\n",
    "6. **Tabel met Metrics**:\n",
    "   - De code creëert een tabel die de berekende evaluatiemetrics en hun bijbehorende waarden weergeeft. Hiervoor wordt de `tabulate`-bibliotheek gebruikt om de metrics als een tabel met koppen weer te geven.\n",
    "\n",
    "De resulterende tabel biedt een duidelijk en georganiseerd overzicht van hoe goed het geoptimaliseerde neuronaal netwerkmodel presteert op het gebied van nauwkeurigheid, precisie, recall en F1-score. De confusion matrix biedt aanvullende inzichten in de prestaties van het model door te laten zien hoe het voorbeelden classificeert voor elke klasse in de dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+\n",
      "| Error Metrics | Values |\n",
      "+---------------+--------+\n",
      "|   Accuracy    |  1.0   |\n",
      "|   Precision   |  1.0   |\n",
      "|    Recall     |  1.0   |\n",
      "|   F1-score    |  1.0   |\n",
      "+---------------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Training the classification model with the best hyperparameters\n",
    "best_activation_function, best_hidden_layer_size, best_solver = best_hyperparameters\n",
    "best_clf = MLPClassifier(hidden_layer_sizes=(best_hidden_layer_size,), activation=best_activation_function, solver=best_solver, max_iter=2000, random_state=42)\n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions for the testdata\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Calculate and print the error metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')  # 'weighted' is handy for multiclass classification\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a list of error metrics and their corresponding values\n",
    "metrics_values = [\n",
    "    [\"Accuracy\", accuracy],\n",
    "    [\"Precision\", precision],\n",
    "    [\"Recall\", recall],\n",
    "    [\"F1-score\", f1],\n",
    "]\n",
    "# Printing the tabel with classification metrics\n",
    "print(tabulate(metrics_values, headers=[\"Error Metrics\", \"Values\"], tablefmt=\"pretty\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix met Descriptieve Klasselabels\n",
    "\n",
    "Deze code-cel is gewijd aan het opstellen van een confusion matrix met mensvriendelijke klasselabels voor de Iris-dataset. De Iris-dataset bevat drie soorten irisbloemen: Setosa, Versicolor en Virginica. De code vertaalt de standaardklasselabels naar mensvriendelijke labels en presenteert deze in de confusion matrix.\n",
    "\n",
    "1. **Definiëren van Mensvriendelijke Klasselabels**:\n",
    "   - Het eerste deel van de code definieert mensvriendelijke klasselabels voor de Iris-dataset. Hier worden de labels \"Setosa,\" \"Versicolor,\" en \"Virginica\" toegewezen aan respectievelijk de klassen 0, 1 en 2.\n",
    "\n",
    "2. **Creëren van de Confusion Matrix**:\n",
    "   - Vervolgens wordt een lijst van lijsten (`conf_matrix_values`) gemaakt om de confusion matrix te construeren. Elk element in deze lijst bevat een descriptieve klassenaam, gevolgd door een beschrijving van het type correcte of foutieve classificatie (bijvoorbeeld \"True Positive\" of \"False Negative\").\n",
    "   - De waarden in de confusion matrix (bijvoorbeeld het aantal ware positieven) worden opgehaald uit de oorspronkelijke `conf_matrix` en gekoppeld aan de descriptieve klasselabels.\n",
    "\n",
    "3. **Tabel van de Confusion Matrix**:\n",
    "   - Tot slot wordt de confusion matrix als een geformatteerde tabel weergegeven. De `tabulate`-bibliotheek wordt gebruikt om de mensvriendelijke klasselabels en de bijbehorende waarden te presenteren.\n",
    "   \n",
    "   Het resultaat is een heldere en begrijpelijke weergave van de confusion matrix met begrijpelijke klasselabels. Dit vergemakkelijkt de interpretatie van de prestaties van een classificatiemodel, vooral voor iemand die niet bekend is met de standaardklasselabels van de Iris-dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+--------+\n",
      "|      Confusion Matrix       | Values |\n",
      "+-----------------------------+--------+\n",
      "|   Setosa (True Positive)    |   10   |\n",
      "|   Setosa (False Negative)   |   0    |\n",
      "|   Setosa (False Positive)   |   0    |\n",
      "| Versicolor (False Positive) |   0    |\n",
      "| Versicolor (True Positive)  |   9    |\n",
      "| Versicolor (False Negative) |   0    |\n",
      "| Virginica (False Positive)  |   0    |\n",
      "| Virginica (False Negative)  |   0    |\n",
      "|  Virginica (True Positive)  |   11   |\n",
      "+-----------------------------+--------+\n"
     ]
    }
   ],
   "source": [
    "# Define human-friendly class labels for the iris dataset\n",
    "class_labels = [\"Setosa\", \"Versicolor\", \"Virginica\"]\n",
    "\n",
    "# Create a list of lists for the confusion matrix with descriptive class labels\n",
    "conf_matrix_values = [\n",
    "    [f\"{class_labels[0]} (True Positive)\", conf_matrix[0, 0]],\n",
    "    [f\"{class_labels[0]} (False Negative)\", conf_matrix[0, 1]],\n",
    "    [f\"{class_labels[0]} (False Positive)\", conf_matrix[0, 2]],\n",
    "    [f\"{class_labels[1]} (False Positive)\", conf_matrix[1, 0]],\n",
    "    [f\"{class_labels[1]} (True Positive)\", conf_matrix[1, 1]],\n",
    "    [f\"{class_labels[1]} (False Negative)\", conf_matrix[1, 2]],\n",
    "    [f\"{class_labels[2]} (False Positive)\", conf_matrix[2, 0]],\n",
    "    [f\"{class_labels[2]} (False Negative)\", conf_matrix[2, 1]],\n",
    "    [f\"{class_labels[2]} (True Positive)\", conf_matrix[2, 2]],\n",
    "]\n",
    "\n",
    "# Print the confusion matrix as a table\n",
    "print(tabulate(conf_matrix_values, headers=[\"Confusion Matrix\", \"Values\"], tablefmt=\"pretty\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
