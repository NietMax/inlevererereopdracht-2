{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze code-cel begint met het importeren van de benodigde Python-bibliotheken. Hier zijn de belangrijkste elementen die in deze cel gebeuren:\n",
    "\n",
    "- We importeren `numpy` als np voor numerieke berekeningen.\n",
    "- We gebruiken de `load_iris` functie van scikit-learn om de Iris-dataset te laden. Deze dataset wordt gebruikt voor het evalueren van het neuraal netwerk.\n",
    "- We importeren de `train_test_split` functie om de dataset in trainings- en testgegevens te splitsen.\n",
    "- We importeren `MLPRegressor` van scikit-learn voor het bouwen van een regressie-gebaseerd meerlagig perceptron neuronaal netwerk.\n",
    "- Tot slot onderdrukken we alle waarschuwingen om de uitvoer opgeruimd te houden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports for the hyperparameter optimization\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Ignoring all warnings because it clutters the space where the results are supposed to go in to\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze code-cel behandelt het volgende:\n",
    "\n",
    "- We laden de Iris-dataset met de `load_iris()` functie en slaan deze op in de `data` variabele.\n",
    "- We splitsen de dataset in kenmerken `(X)` en doelwaarden `(y)`. Dit zijn de gegevens die het neurale netwerk zal gebruiken voor training.\n",
    "- Vervolgens gebruiken we de `train_test_split` functie om de gegevens te verdelen in training en testsets. De trainingset bevat 80% van de gegevens en wordt gebruikt om het model te trainen, terwijl de testset 20% van de gegevens bevat en wordt gebruikt om de prestaties van het model te evalueren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're still using the iris dataset for this assignment\n",
    "data = load_iris()\n",
    "\n",
    "# Splitting the data into training and testing data\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In deze code-cel definiëren we de hyperparameters die we willen onderzoeken met ons genetisch algoritme:\n",
    "\n",
    "- __Activeringsfuncties__: We overwegen vier verschillende activeringsfuncties die in neurale netwerken kunnen worden gebruikt. Dit zijn `logistic`, `tanh`, `relu`, en `identity`.\n",
    "\n",
    "- __Grootte van verborgen lagen (hidden layers)__: We beschouwen verschillende groottes voor de verborgen lagen van het neurale netwerk. Deze maten worden gedefinieerd als een lijst van getallen, bijvoorbeeld `[10, 20, 30, 40]`. Elke waarde vertegenwoordigt het aantal neuronen in de verborgen laag.\n",
    "\n",
    "- __Oplossers (solvers)__: We overwegen drie verschillende optimalisatiealgoritmen (solvers) om de optimale gewichten in het neurale netwerk te vinden. Dit zijn `lbfgs`, `sgd`, en `adam`. We gebruiken de standaard leersnelheid voor elk van deze solvers.\n",
    "\n",
    "Deze hyperparameters zullen door het genetisch algoritme worden geoptimaliseerd om de best mogelijke configuratie voor het neurale netwerk te vinden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the hyperparameters that we want to test\n",
    "activation_functions = ['logistic', 'tanh', 'relu', 'identity']\n",
    "# The hidden layer sizes are defined as a list of tuples, where each tuple represents a hidden layer\n",
    "hidden_layer_sizes = [10, 20, 30, 40]\n",
    "# The solvers are the optimizers that are used to find the optimal weights\n",
    "# We're using the default learning rate for each solver\n",
    "solvers = ['lbfgs', 'sgd', 'adam']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In deze code-cel definiëren we de belangrijkste functies en het genetisch algoritme dat de optimale hyperparameters voor het regressie-gebaseerde neuraal netwerk zal vinden. Laten we het in delen bespreken:\n",
    "\n",
    "- __evaluate_individual__: Dit is een functie die de nauwkeurigheid van een individuele configuratie van hyperparameters evalueert. We creëren een MLPRegressor met de opgegeven hyperparameters, trainen het op de trainingset en evalueren de score op de testset.\n",
    "\n",
    "- __genetic_algorithm__: Dit is de kern van het genetische algoritme. We beginnen met het genereren van een willekeurige populatie van individuen met verschillende hyperparameters. Vervolgens herhalen we het genetische algoritme over een aantal generaties. In elke generatie selecteren we de beste individuen op basis van hun prestaties en genereren we een nieuwe populatie door kruising en mutatie. Uiteindelijk vinden we het individu met de beste hyperparameters voor het regressieneuraal netwerk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function that evaluates the accuracy of an individual\n",
    "def evaluate_individual(activation_function, hidden_layer_size, solver):\n",
    "    clf = MLPRegressor(hidden_layer_sizes=(hidden_layer_size,), activation=activation_function, solver=solver, max_iter=2000, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    return accuracy\n",
    "\n",
    "# The genetic algorithm that finds the best individual\n",
    "def genetic_algorithm(population_size, generations):\n",
    "    population = []\n",
    "\n",
    "    # Creating the initial population\n",
    "    for _ in range(population_size):\n",
    "        activation_function = np.random.choice(activation_functions)\n",
    "        hidden_layer_size = np.random.choice(hidden_layer_sizes)\n",
    "        solver = np.random.choice(solvers)\n",
    "        individual = (activation_function, hidden_layer_size, solver)\n",
    "        population.append(individual)\n",
    "\n",
    "    # Running the genetic algorithm\n",
    "    for generation in range(generations):\n",
    "        scores = [evaluate_individual(activation_function, hidden_layer_size, solver) for activation_function, hidden_layer_size, solver in population]\n",
    "        selected_indices = np.argsort(scores)[::-1][:int(population_size * 0.2)]\n",
    "        selected_population = [population[i] for i in selected_indices]\n",
    "\n",
    "        # Creating the new population\n",
    "        new_population = []\n",
    "        for _ in range(population_size):\n",
    "            index1, index2 = np.random.choice(len(selected_population), size=2, replace=False)\n",
    "            parent1 = selected_population[index1]\n",
    "            parent2 = selected_population[index2]\n",
    "            parent1_activation_function, parent1_hidden_layer_size, parent1_solver = parent1\n",
    "            parent2_activation_function, parent2_hidden_layer_size, parent2_solver = parent2\n",
    "            child = (parent1_activation_function, parent2_hidden_layer_size, parent2_solver)\n",
    "            new_population.append(child)\n",
    "\n",
    "        # Mutating the new population\n",
    "        population = new_population\n",
    "\n",
    "    # Finding the best individual\n",
    "    best_individual = max(population, key=lambda ind: evaluate_individual(ind[0], ind[1], ind[2]))\n",
    "    return best_individual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze code-cel voert het genetisch algoritme uit en drukt de optimale hyperparameters af die zijn gevonden. De optimale hyperparameters vertegenwoordigen de beste combinatie voor het regressieneuraal netwerk dat is aangepast aan de gegeven dataset en configuratie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimale hyperparameters: ('tanh', 10, 'lbfgs')\n"
     ]
    }
   ],
   "source": [
    "# Running the genetic algorithm and printing the results\n",
    "best_hyperparameters_regressor = genetic_algorithm(population_size=50, generations=10)\n",
    "print(\"Optimal hyperparameters:\", best_hyperparameters_regressor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
